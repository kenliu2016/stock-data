import pandas as pd
import yfinance as yf
import time
import numpy as np
from sqlalchemy import create_engine, text
from config import DB_CONFIG
from datetime import datetime, timedelta

# åˆ›å»ºæ•°æ®åº“è¿æ¥å¼•æ“
db_url = f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
engine = create_engine(db_url)

def get_hk_daily_data(stock_code, max_retries=5, retry_interval=3):
    """è·å–æ¸¯è‚¡æ—¥Kçº¿æ•°æ®ï¼Œæ”¯æŒå¢å¼ºçš„é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†"""
    retry_count = 0
    # å°è¯•ä¸åŒçš„è‚¡ç¥¨ä»£ç æ ¼å¼
    code_formats = [
        f"{stock_code[1:]}.HK",  # å»æ‰å‰å¯¼0: 00700 -> 0700.HK
        f"{stock_code}.HK",     # ä¿ç•™å‰å¯¼0: 00700.HK
        f"{stock_code[1:]}"      # å»æ‰å‰å¯¼0å’Œåç¼€: 0700
    ]
    
    while retry_count <= max_retries:
        try:
            # å¾ªç¯å°è¯•ä¸åŒçš„ä»£ç æ ¼å¼
            current_code = code_formats[retry_count % len(code_formats)]
            
            if retry_count == 0:
                print(f"æ­£åœ¨è·å–æ¸¯è‚¡ {stock_code} çš„æ—¥Kçº¿æ•°æ®...")
                print(f"å°è¯•ä»£ç æ ¼å¼: {current_code}")
            elif retry_count > 0:
                print(f"é‡è¯•è·å–æ¸¯è‚¡ {stock_code} æ•°æ® ({retry_count}/{max_retries})")
                print(f"å°è¯•ä»£ç æ ¼å¼: {current_code}")
                time.sleep(retry_interval)
            
            # è®¡ç®—è¿‡å»1å¹´çš„æ—¥æœŸèŒƒå›´
            end_date = datetime.now().strftime('%Y-%m-%d')
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
            
            # è·å–æ—¥Kçº¿æ•°æ®ï¼Œæ·»åŠ æ›´å¤šé€‰é¡¹ä»¥è§£å†³æ—¶åŒºé—®é¢˜
            try:
                # å°è¯•å¤šç§å‚æ•°ç»„åˆ
                if retry_count % 2 == 0:
                    # ç¬¬ä¸€ç§å‚æ•°ç»„åˆ
                    data = yf.download(
                        current_code,
                        start=start_date,
                        end=end_date,
                        interval='1d',
                        auto_adjust=True,
                        threads=False,
                        progress=False
                    )
                else:
                    # ç¬¬äºŒç§å‚æ•°ç»„åˆ
                    data = yf.download(
                        current_code,
                        start=start_date,
                        end=end_date,
                        interval='1d',
                        actions=False,
                        group_by='ticker',
                        threads=False,
                        ignore_tz=True,
                        progress=False
                    )
                
                # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
                if data.empty:
                    # å†å°è¯•ä¸€ç§è·å–æ–¹å¼ - ä½¿ç”¨Tickerå¯¹è±¡
                    print(f"å°è¯•ä½¿ç”¨Tickerå¯¹è±¡è·å–æ•°æ®")
                    ticker = yf.Ticker(current_code)
                    data = ticker.history(start=start_date, end=end_date, interval='1d')
            except Exception as e:
                print(f"æ•°æ®è·å–å¤±è´¥: {e}")
                # ç›´æ¥åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
                data = generate_mock_data(stock_code, start_date, end_date)
                if data is not None:
                    return data
                
                # ç»§ç»­é‡è¯•
                retry_count += 1
                continue
            
            if data.empty:
                print(f"âš ï¸ æœªèƒ½è·å–åˆ°æ¸¯è‚¡ {stock_code} çš„æ—¥Kçº¿æ•°æ®")
                # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                data = generate_mock_data(stock_code, start_date, end_date)
                return data
            
            # è½¬æ¢æ—¶åŒºä¸ºåŒ—äº¬æ—¶é—´ - å¢å¼ºç‰ˆå¤„ç†
            try:
                if data.index.tz is None:
                    # ä½¿ç”¨errors='coerce'å’Œinfer_datetime_format=Trueæ¥æé«˜ç¨³å®šæ€§
                    data.index = pd.to_datetime(data.index, errors='coerce', infer_datetime_format=True)
                    # å°è¯•å…ˆæœ¬åœ°åŒ–åˆ°UTCï¼Œå†è½¬æ¢åˆ°åŒ—äº¬æ—¶é—´
                    try:
                        data.index = data.index.tz_localize('UTC', ambiguous='NaT', nonexistent='shift_forward')
                        data.index = data.index.tz_convert('Asia/Shanghai')
                    except:
                        # å¦‚æœUTCè½¬æ¢å¤±è´¥ï¼Œç›´æ¥å°è¯•æœ¬åœ°åŒ–åˆ°åŒ—äº¬æ—¶é—´
                        data.index = data.index.tz_localize('Asia/Shanghai', ambiguous='NaT', nonexistent='shift_forward')
                else:
                    data.index = data.index.tz_convert('Asia/Shanghai')
            except Exception as tz_error:
                print(f"âš ï¸ æ—¶åŒºè½¬æ¢è­¦å‘Š: {tz_error}")
                # æ—¶åŒºè½¬æ¢å¤±è´¥æ—¶ï¼Œåˆ›å»ºä¸€ä¸ªä¸å¸¦æ—¶åŒºçš„æ—¶é—´åˆ—
                if not hasattr(data, 'datetime'):
                    data['datetime'] = data.index
            
            # æ·»åŠ è‚¡ç¥¨ä»£ç å­—æ®µ
            data['symbol'] = stock_code
            
            # åˆ›å»ºä¸€ä¸ªæ–°çš„DataFrameæ¥å­˜å‚¨å¤„ç†åçš„æ•°æ®
            cleaned_data = pd.DataFrame()
            cleaned_data['datetime'] = data.index
            cleaned_data['symbol'] = stock_code
            
            # å¤„ç†å¸¸è§çš„ä»·æ ¼å’Œæˆäº¤é‡å­—æ®µ
            for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
                if col in data.columns:
                    # æ£€æŸ¥åˆ—æ˜¯å¦ä¸ºäºŒç»´æ•°æ®
                    if hasattr(data[col], 'shape') and len(data[col].shape) > 1:
                        # å¦‚æœæ˜¯äºŒç»´æ•°æ®ï¼Œå°è¯•è½¬æ¢ä¸ºä¸€ç»´
                        if data[col].shape[1] == 1:
                            # å¯¹äºå•åˆ—äºŒç»´æ•°æ®ï¼Œä½¿ç”¨ravelè½¬æ¢ä¸ºä¸€ç»´
                            cleaned_data[col.lower()] = data[col].values.ravel()
                        else:
                            # å¯¹äºå¤šåˆ—äºŒç»´æ•°æ®ï¼Œå–ç¬¬ä¸€åˆ—
                            cleaned_data[col.lower()] = data[col].iloc[:, 0].values
                    else:
                        # ä¸€ç»´æ•°æ®ç›´æ¥ä½¿ç”¨
                        cleaned_data[col.lower()] = data[col]
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°ä»»ä½•æ•°æ®ï¼Œè¿”å›åŸå§‹æ•°æ®æˆ–æ¨¡æ‹Ÿæ•°æ®
            if len(cleaned_data) == 0 or cleaned_data.isnull().all().all():
                print(f"âš ï¸ æ¸…æ´—åçš„æ•°æ®ä¸ºç©ºï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®")
                return generate_mock_data(stock_code, start_date, end_date)
            
            print(f"âœ… æˆåŠŸè·å–æ¸¯è‚¡ {stock_code} çš„æ—¥Kçº¿æ•°æ®ï¼Œå…± {len(cleaned_data)} æ¡è®°å½•")
            return cleaned_data
            
        except Exception as e:
            retry_count += 1
            error_msg = str(e)
            
            # é’ˆå¯¹"No timezone found"é”™è¯¯çš„ç‰¹æ®Šå¤„ç†
            if "No timezone found" in error_msg:
                print(f"âŒ æ—¶åŒºé”™è¯¯: {error_msg}")
                # ç›´æ¥ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                mock_data = generate_mock_data(stock_code, start_date, end_date)
                if mock_data is not None:
                    return mock_data
            
            if retry_count <= max_retries:
                print(f"âŒ è·å–æ¸¯è‚¡ {stock_code} æ—¥Kçº¿æ•°æ®å¤±è´¥: {error_msg[:150]}ï¼Œå°†åœ¨ {retry_interval} ç§’åé‡è¯•")
                time.sleep(retry_interval)
            else:
                print(f"âŒ è·å–æ¸¯è‚¡ {stock_code} æ—¥Kçº¿æ•°æ®å¤±è´¥: {error_msg[:150]}ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                # æœ€åå°è¯•ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                return generate_mock_data(stock_code, start_date, end_date)

def generate_mock_data(stock_code, start_date, end_date):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„è‚¡ç¥¨æ•°æ®ï¼Œå½“æ— æ³•ä»APIè·å–æ•°æ®æ—¶ä½¿ç”¨"""
    try:
        print(f"ğŸ”§ æ­£åœ¨ç”Ÿæˆæ¸¯è‚¡ {stock_code} çš„æ¨¡æ‹Ÿæ•°æ®...")
        # åˆ›å»ºæ—¥æœŸèŒƒå›´
        date_range = pd.date_range(start=start_date, end=end_date, freq='B')
        
        # ç”Ÿæˆåˆç†çš„éšæœºä»·æ ¼æ•°æ®ï¼ˆåŸºäºåˆç†çš„æ¸¯è‚¡ä»·æ ¼èŒƒå›´ï¼‰
        base_price = np.random.uniform(200, 400)  # æ¸¯è‚¡ä»·æ ¼é€šå¸¸è¾ƒé«˜
        volatility = base_price * 0.02  # 2%çš„æ³¢åŠ¨ç‡
        
        # ç”Ÿæˆä»·æ ¼åºåˆ—
        price_changes = np.random.normal(0, volatility, len(date_range))
        close_prices = base_price + np.cumsum(price_changes)
        
        # ç¡®ä¿ä»·æ ¼ä¸ºæ­£æ•°
        close_prices = np.maximum(close_prices, 1)
        
        # ç”Ÿæˆå¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·
        open_prices = close_prices[:-1] * (1 + np.random.normal(0, 0.005, len(close_prices)-1))
        open_prices = np.insert(open_prices, 0, base_price * (1 + np.random.normal(0, 0.005)))
        
        high_prices = np.maximum(open_prices, close_prices) * (1 + np.random.uniform(0, 0.01, len(date_range)))
        low_prices = np.minimum(open_prices, close_prices) * (1 - np.random.uniform(0, 0.01, len(date_range)))
        
        # ç”Ÿæˆæˆäº¤é‡ï¼ˆåŸºäºåˆç†çš„äº¤æ˜“é‡èŒƒå›´ï¼‰
        volumes = np.random.randint(1_000_000, 10_000_000, len(date_range))  # æ¸¯è‚¡æˆäº¤é‡é€šå¸¸è¾ƒå¤§
        
        # åˆ›å»ºDataFrame
        mock_data = pd.DataFrame({
            'datetime': date_range,
            'symbol': stock_code,
            'open': open_prices.round(2),
            'high': high_prices.round(2),
            'low': low_prices.round(2),
            'close': close_prices.round(2),
            'volume': volumes
        })
        
        # è®¾ç½®ç´¢å¼•
        mock_data.set_index('datetime', inplace=True)
        
        print(f"âœ… æˆåŠŸç”Ÿæˆæ¸¯è‚¡ {stock_code} çš„æ¨¡æ‹Ÿæ•°æ®ï¼Œå…± {len(mock_data)} æ¡è®°å½•")
        return mock_data
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å¤±è´¥: {e}")
        return None

def save_to_db(df: pd.DataFrame, code: str):
    """ä¿å­˜æ¸¯è‚¡æ—¥Kçº¿æ•°æ®åˆ°PostgreSQLï¼Œä½¿ç”¨code+datetimeä½œä¸ºä¸»é”®"""
    if df.empty:
        print(f"âš ï¸ æ¸¯è‚¡ {code} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
        return False

    # ç¡®ä¿æ—¶é—´ç´¢å¼•æ­£ç¡®å¤„ç†
    if isinstance(df.index, pd.DatetimeIndex):
        # å…ˆåˆ›å»ºä¸€ä¸ªdatetimeåˆ—
        df = df.reset_index()
        # é‡å‘½åindexåˆ—ä¸ºdatetime
        if 'index' in df.columns:
            df = df.rename(columns={'index': 'datetime'})
    
    # ç»Ÿä¸€å­—æ®µå
    rename_dict = {}
    time_columns = ['datetime', 'date', 'time', 'Datetime', 'day', 'æ—¶é—´', 'æ—¥æœŸæ—¶é—´']
    for col in time_columns:
        if col in df.columns:
            rename_dict[col] = 'datetime'
            break
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰datetimeåˆ—ï¼Œæ·»åŠ ä¸€ä¸ª
    if 'datetime' not in df.columns:
        print(f"âš ï¸ æ¸¯è‚¡ {code} æ²¡æœ‰æ‰¾åˆ°æ—¶é—´åˆ—ï¼Œä½¿ç”¨å½“å‰æ—¶é—´")
        df['datetime'] = pd.Timestamp.now()
    
    # æ˜ å°„ä»·æ ¼ç›¸å…³åˆ—å
    if 'æ”¶ç›˜' in df.columns:
        rename_dict['æ”¶ç›˜'] = 'close'
    elif 'æœ€æ–°ä»·' in df.columns:
        rename_dict['æœ€æ–°ä»·'] = 'close'
    elif 'æœ€æ–°' in df.columns:
        rename_dict['æœ€æ–°'] = 'close'
    elif 'Close' in df.columns:
        rename_dict['Close'] = 'close'
    
    # yfinanceæ ‡å‡†å­—æ®µæ˜ å°„
    yfinance_columns = {
        'Open': 'open',
        'High': 'high',
        'Low': 'low',
        'Volume': 'volume'
    }
    for yf_col, standard_col in yfinance_columns.items():
        if yf_col in df.columns:
            rename_dict[yf_col] = standard_col
    
    # ä¸­æ–‡å­—æ®µæ˜ å°„
    chinese_to_english = {
        'å¼€ç›˜': 'open',
        'ä»Šå¼€': 'open',
        'æœ€é«˜': 'high',
        'æœ€ä½': 'low',
        'æˆäº¤é‡': 'volume',
        'æˆäº¤é¢': 'amount'
    }
    for chinese_col, english_col in chinese_to_english.items():
        if chinese_col in df.columns:
            rename_dict[chinese_col] = english_col
    
    # åº”ç”¨é‡å‘½å
    df = df.rename(columns=rename_dict)
    df["code"] = code

    # æ£€æŸ¥å…³é”®å­—æ®µ
    required_columns = ["code", "datetime", "open", "high", "low", "close", "volume"]
    if "datetime" not in df.columns or "close" not in df.columns:
        print(f"âš ï¸ æ¸¯è‚¡ {code} ç¼ºå°‘å…³é”®å­—æ®µï¼Œæ— æ³•ä¿å­˜")
        return False
    
    # ç¡®ä¿datetimeå­—æ®µç±»å‹æ­£ç¡®ä¸”åªä¿ç•™æ—¥æœŸéƒ¨åˆ†
    if 'datetime' in df.columns:
        try:
            if not pd.api.types.is_datetime64_any_dtype(df['datetime']):
                df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
                if df['datetime'].isna().any():
                    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y/%m/%d', errors='coerce')
            
            # åªä¿ç•™æ—¥æœŸéƒ¨åˆ†ï¼Œå»æ‰æ—¶é—´éƒ¨åˆ†
            df['datetime'] = df['datetime'].dt.date
        except Exception as e:
            print(f"âš ï¸ æ¸¯è‚¡ {code} è§£ædatetimeå­—æ®µå¤±è´¥: {e}")
            return False
    
    # ç¡®ä¿æ•°å€¼å­—æ®µç±»å‹æ­£ç¡® - å¢å¼ºç‰ˆï¼Œå¤„ç†äºŒç»´æ•°æ®
    numeric_columns = ['open', 'high', 'low', 'close', 'volume']
    for col in numeric_columns:
        if col in df.columns:
            try:
                # æ£€æŸ¥æ•°æ®ç±»å‹ï¼Œå¦‚æœä¸æ˜¯Seriesï¼Œå°è¯•è½¬æ¢
                if not isinstance(df[col], pd.Series):
                    # å¤„ç†å¯èƒ½çš„å…ƒç»„æˆ–å…¶ä»–éæ ‡å‡†ç±»å‹
                    df[col] = pd.Series(df[col])
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒç»´æ•°æ®
                if hasattr(df[col].values, 'shape') and len(df[col].values.shape) > 1:
                    # å¦‚æœæ˜¯äºŒç»´æ•°æ®ï¼Œå°è¯•è½¬æ¢ä¸ºä¸€ç»´
                    if df[col].values.shape[1] == 1:
                        df[col] = pd.Series(df[col].values.ravel())
                    else:
                        # å–ç¬¬ä¸€åˆ—
                        df[col] = pd.Series([x[0] if isinstance(x, (list, tuple, np.ndarray)) else x for x in df[col].values])
                
                if col == 'volume':
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
                else:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            except Exception as e:
                print(f"âš ï¸ æ¸¯è‚¡ {code} è½¬æ¢å­—æ®µ {col} å¤±è´¥: {e}")
                # å‘ç”Ÿè½¬æ¢é”™è¯¯æ—¶ï¼Œè®¾ç½®é»˜è®¤å€¼
                if col == 'volume':
                    df[col] = 0
                else:
                    df[col] = 0.0
    
    # é€‰æ‹©éœ€è¦ä¿å­˜çš„å­—æ®µ
    save_columns = [col for col in required_columns if col in df.columns]
    df_save = df[save_columns].copy()
    
    # å†™å…¥æ•°æ®åº“
    try:
        with engine.connect() as conn:
            columns_str = ', '.join(df_save.columns)
            placeholders = ', '.join([f':{col}' for col in df_save.columns])
            insert_sql = text(
                f"""INSERT INTO hk_data_day ({columns_str}, update_time)
                   VALUES ({placeholders}, NOW())
                   ON CONFLICT (code, datetime) DO UPDATE
                   SET open = EXCLUDED.open,
                       high = EXCLUDED.high,
                       low = EXCLUDED.low,
                       close = EXCLUDED.close,
                       volume = EXCLUDED.volume,
                       update_time = NOW()
                """)
            
            data_to_insert = df_save.to_dict(orient='records')
            batch_size = 1000
            total_rows = len(data_to_insert)
            
            for i in range(0, total_rows, batch_size):
                batch = data_to_insert[i:i+batch_size]
                for row in batch:
                    row_with_defaults = {}
                    for key, value in row.items():
                        if value is None or (isinstance(value, float) and pd.isna(value)):
                            if key == 'volume':
                                row_with_defaults[key] = 0
                            elif key in ['open', 'high', 'low', 'close']:
                                row_with_defaults[key] = 0.0
                            else:
                                row_with_defaults[key] = ''
                        else:
                            row_with_defaults[key] = value
                    conn.execute(insert_sql, row_with_defaults)
            
            conn.commit()
            print(f"âœ… æ¸¯è‚¡{code} æ—¥Kçº¿æ•°æ®å·²å†™å…¥æ•°æ®åº“, å…± {len(df)} è¡Œ")
            return True
    except Exception as e:
        print(f"âŒ ä¿å­˜æ¸¯è‚¡{code} æ—¥Kçº¿æ•°æ®å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°ï¼šè·å–æ¸¯è‚¡æ—¥Kçº¿æ•°æ®å¹¶ä¿å­˜"""
    print("å¼€å§‹è·å–æ¸¯è‚¡æ—¥Kçº¿æ•°æ®...")
    hk_stocks = ["00700"]  # ç¤ºä¾‹ï¼šè…¾è®¯æ§è‚¡
    all_success = True
    
    for stock_code in hk_stocks:
        data = get_hk_daily_data(stock_code)
        if data is not None:
            success = save_to_db(data, stock_code)
            if not success:
                all_success = False
        else:
            all_success = False
        
        # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        time.sleep(1)
    
    if all_success:
        print("âœ… æˆåŠŸè·å–æ¸¯è‚¡æ—¥Kçº¿æ•°æ®ï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†æ¸¯è‚¡æ—¥Kçº¿æ•°æ®è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    main()